# --- Required (one of these) ---

# Option A: Anthropic API key — used by claude-agent-sdk for all coding agents
ANTHROPIC_API_KEY=sk-ant-api03-...

# Option B: Claude Code subscription OAuth token (run `claude setup-token` to get it)
# Uses your Pro/Max subscription credits instead of API billing
# CLAUDE_CODE_OAUTH_TOKEN=sk-ant-oat01-...

# Option C: Open-source models (DeepSeek, Qwen, Llama, MiniMax, etc.)
# Access 200+ open-source and proprietary models via OpenRouter, OpenAI, or Google
# Configure one or more API keys:

# OpenRouter (recommended - 200+ models including DeepSeek, Qwen, Llama, MiniMax)
# OPENROUTER_API_KEY=sk-or-v1-...

# OpenAI (GPT-4, GPT-4o, etc.)
# OPENAI_API_KEY=sk-...

# Google Gemini
# GOOGLE_API_KEY=...

# Note: Can reuse ANTHROPIC_API_KEY from above for Claude models via OpenCode

# --- Optional: GitHub integration ---

# GitHub personal access token (repo scope) — for draft PR creation
# Only needed if using repo_url + enable_github_pr
GH_TOKEN=ghp_...

# --- Optional: AgentField server ---

# Override the control plane URL (default: http://control-plane:8080 in Docker,
# http://localhost:8080 when running bare metal)
# Set this to use an already-running control plane instead of Docker's:
# AGENTFIELD_SERVER=http://host.docker.internal:8080
# AGENTFIELD_SERVER=http://localhost:8080

# Node ID for this agent (default: swe-planner)
# NODE_ID=swe-planner

# Port the agent listens on (default: 8003)
# PORT=8003

# --- Optional: Model configuration ---

# Runtime/model selection is configured via API request config (V2):
# {
#   "runtime": "claude_code" | "open_code",
#   "models": {
#     "default": "sonnet or provider/model-id",
#     "coder": "provider/model-id",
#     "qa": "provider/model-id"
#   }
# }
#
# Runtime mapping:
#   claude_code -> Claude backend
#   open_code -> OpenCode backend
#
# Legacy keys are removed: ai_provider, preset, model, and all *_model fields.
#
# Example open runtime request config:
# {"runtime": "open_code", "models": {"default": "deepseek/deepseek-chat"}}
#
# Example Claude runtime request config:
# {"runtime": "claude_code", "models": {"default": "sonnet", "coder": "opus"}}

# Available open runtime model IDs (format: provider/model-name):
#   deepseek/deepseek-chat      # DeepSeek via OpenRouter
#   minimax/minimax-m2.5        # MiniMax M2.5 via OpenRouter
#   qwen/qwen-2.5-72b-instruct  # Qwen via OpenRouter
#   openai/gpt-4o               # GPT-4 via OpenAI
#   anthropic/claude-sonnet-4   # Claude via Anthropic
